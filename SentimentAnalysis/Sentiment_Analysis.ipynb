{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4df5ee4f",
   "metadata": {},
   "source": [
    "# SENTIMENT ANALYSIS ON HOTEL RATING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc9a7d3",
   "metadata": {},
   "source": [
    "### Hotel Name: Occidental Grand Xcaret & Royal Club & HotelID: 260444"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5788c488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from keras import models\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a358911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data set\n",
    "df = pd.read_csv('Reviews.csv') # Converted 260444.json to Reviews.csv by using mongoDB compass\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a484d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required dataset for training\n",
    "\"\"\" We need only two columns Content and Ratings.Overall \"\"\"\n",
    "reqData = df[['Content', 'Ratings.Overall']]\n",
    "reqData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188e9a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Exploration\n",
    "reqData.info()\n",
    "reqData.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8d8c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check For Null values\n",
    "\"\"\" There is no null values \"\"\"\n",
    "reqData.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec961b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for unique values\n",
    "reqData['Ratings.Overall'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763a569a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Visualization\n",
    "\"\"\" We can see that most of the people give 5 Rating \"\"\"\n",
    "reqData['Ratings.Overall'].value_counts()\n",
    "num = [5,4,3,2,1]\n",
    "plt.bar(num, reqData['Ratings.Overall'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757ae0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "reqData.Content[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd825262",
   "metadata": {},
   "source": [
    "### Data Preprocessing / Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249a2e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing / Cleaning\n",
    "sw = set(stopwords.words('english'))\n",
    "ps = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "ps.stem('jumping')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f906465e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to clean data\n",
    "def cleanText(sample):\n",
    "    sample = sample.lower()\n",
    "    # Remove punctuations\n",
    "    sample = re.sub(\"[^a-zA-Z]+\", ' ', sample)\n",
    "    # Tokenizing sample (split every word)\n",
    "    sample = sample.split()\n",
    "    # Remove stopwords\n",
    "    sample = [s for s in sample if s not in sw] # List comprehension\n",
    "    # Stemmimg (convert words to root words: jumping-jump) \n",
    "    sample = [ps.stem(s) for s in sample]\n",
    "    # Lemmatization it reduces size of vocabolary.\n",
    "    sample = [lemmatizer.lemmatize(s) for s in sample]\n",
    "    # Joins words\n",
    "    sample = \" \".join(sample)\n",
    "       \n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f1c0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanText(reqData.Content[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b605a085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply cleanText function to DataFrame\n",
    "reqData['CleanedContent'] = reqData['Content'].apply(cleanText)\n",
    "reqData.head()\n",
    "\n",
    "corpus = reqData['CleanedContent'].values #  Convert to Array\n",
    "y = reqData['Ratings.Overall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a592b1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Text data to matrix formate or tabular formate\n",
    "cv = CountVectorizer(ngram_range=(1, 3), max_df=0.5, max_features=30000)\n",
    "tfidf = TfidfTransformer()\n",
    "\n",
    "X = cv.fit_transform(corpus)\n",
    "print(X[0])\n",
    "\n",
    "X = tfidf.fit_transform(X)\n",
    "print(X[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527c63b1",
   "metadata": {},
   "source": [
    "### Create  a Artificial Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1d32e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create  Artificial Neural Network\n",
    "model = models.Sequential([\n",
    "    Dense(128, input_shape=(2020,30000,), activation=\"relu\"),\n",
    "    Dense(64, activation=\"relu\"),\n",
    "    Dense(32, activation=\"relu\"),\n",
    "    Dense(16, activation=\"selu\"),\n",
    "    Dense(6, activation=\"softmax\"),\n",
    "    ])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aeaba4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Compile Model\n",
    "model.compile(\n",
    "    optimizer=\"rmsprop\",\n",
    "    loss = \"sparse_categorical_crossentropy\",\n",
    "    metrics = ['accuracy'],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c299077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train, test and validation\n",
    "xval = X[:500]\n",
    "xtest = X[500:900]\n",
    "xtrain = X[900:]\n",
    "\n",
    "yval = y[:500]\n",
    "ytest = y[500:900]\n",
    "ytrain = y[900:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffa2688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converted data into Array\n",
    "xtrainArr = xtrain.toarray()\n",
    "xtestArr = xtest.toarray()\n",
    "xvalArr = xval.toarray()\n",
    "\n",
    "ytrainArr = np.array(y[900:])\n",
    "yvalArr = np.array(y[:500])\n",
    "ytestArr = np.array(y[500:900])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949e4024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train neural network\n",
    "hist = model.fit(xtrainArr, ytrainArr, batch_size=16, epochs=2, validation_data=(xvalArr, yvalArr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b39317f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = hist.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430a87c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Visualization\n",
    "\"\"\" Here we can adjust our epochs values to overcome model overfitting\"\"\"\n",
    "plt.plot(result['val_accuracy'], label='Val_acc')\n",
    "plt.plot(result['accuracy'], label=\"train_acc\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3c82c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(result['val_loss'], label='Val_loss')\n",
    "plt.plot(result['loss'], label=\"train_los\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2349ab64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate data\n",
    "model.evaluate(xvalArr, yvalArr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d9d4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Our Model\n",
    "yPred = model.predict(xtestArr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38f1252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Comperision DataFrame\n",
    "ypreValues =[]\n",
    "for i in range(0, 400): \n",
    "    val = np.argmax(yPred[i])\n",
    "    ypreValues.append(val)\n",
    "    \n",
    "yPredArr = np.array(ypreValues).reshape(-1, 1)\n",
    "ytestArr = ytestArr.reshape(-1, 1)\n",
    "ids = np.arange(400).reshape(-1, 1)\n",
    "finalMatrix = np.hstack((ids, ytestArr, yPredArr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61deca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a final result csv file\n",
    "final =pd.DataFrame(finalMatrix, columns=['Id','Original_Value','Predicted_value'])  \n",
    "# final.to_csv('Rating_Comperision.csv', index=False)----Already created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f74128",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc09951f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
